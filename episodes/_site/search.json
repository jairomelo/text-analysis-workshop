[
  {
    "objectID": "02-CreatingACorpus.html",
    "href": "02-CreatingACorpus.html",
    "title": "Creating a Corpus",
    "section": "",
    "text": "In this episode, we’re going to create a corpus of texts and prepare it for analysis by performing some standard preprocessing. Because of the nature of R, we will be transforming plain text files into tibbles, which are a modern take on data frames that make data manipulation easier and more intuitive.\nTo better understand what happens when we process a series of books, let’s start with an exercise using Kafka’s short story “Before the Law.”\nFirst, we need to install and load the tidyverse package, which includes dplyr, ggplot2, and other useful packages for data manipulation and visualization.\nIn RStudio, create a new R script (File → New File → R Script) and write the following commands. You can execute each line by placing your cursor on it and pressing Ctrl+Enter:\ninstall.packages(\"tidyverse\")\nlibrary(tidyverse)\nNext, we’ll create a text variable that stores our short story. We’re using tryCatch() to handle any potential errors when reading the file, and the read_lines() function, which is part of the readr package, to read the text file line by line safely.\nbeforethelaw_url &lt;- \"https://raw.githubusercontent.com/jairomelo/text-analysis-workshop/refs/heads/main/episodes/texts/Kafka-beforethelaw.txt\"\n\nbeforethelaw &lt;- tryCatch(\n    read_lines(beforethelaw_url, locale = locale(encoding = \"UTF-8\")),\n    error = function(e) {\n        message(\"Error reading the text: \", e)\n        return(NULL)\n    }\n)\n\nbeforethelaw\n\n[1] \"BEFORE THE LAW\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n[2] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n[3] \"Before the law sits a gatekeeper. To this gatekeeper comes a man from the country who asks to gain entry into the law. But the gatekeeper says that he cannot grant him entry at the moment. The man thinks about it and then asks if he will be allowed to come in sometime later on. “It is possible,” says the gatekeeper, “but not now.” The gate to the law stands open, as always, and the gatekeeper walks to the side, so the man bends over in order to see through the gate into the inside. When the gatekeeper notices that, he laughs and says: “If it tempts you so much, try going inside in spite of my prohibition. But take note. I am powerful. And I am only the lowliest gatekeeper. But from room to room stand gatekeepers, each more powerful than the last. I cannot endure even one glimpse of the third.” The man from the country has not expected such difficulties: the law should always be accessible for everyone, he thinks, but as he now looks more closely at the gatekeeper in his fur coat, at his large pointed nose and his long, thin, black Tartar’s beard, he decides that it would be better to wait until he gets permission to go inside. The gatekeeper gives him a stool and allows him to sit down at the side in front of the gate. There he sits for days and years. He makes many attempts to be let in, and he wears the gatekeeper out with his requests. The gatekeeper often interrogates him briefly, questioning him about his homeland and many other things, but they are indifferent questions, the kind great men put, and at the end he always tells him once more that he cannot let him inside yet. The man, who has equipped himself with many things for his journey, spends everything, no matter how valuable, to win over the gatekeeper. The latter takes it all but, as he does so, says, “I am taking this only so that you do not think you have failed to do anything.” During the many years the man observes the gatekeeper almost continuously. He forgets the other gatekeepers, and this first one seems to him the only obstacle for entry into the law. He curses the unlucky circumstance, in the first years thoughtlessly and out loud; later, as he grows old, he only mumbles to himself. He becomes childish and, since in the long years studying the gatekeeper he has also come to know the fleas in his fur collar, he even asks the fleas to help him persuade the gatekeeper. Finally his eyesight grows weak, and he does not know whether things are really darker around him or whether his eyes are merely deceiving him. But he recognizes now in the darkness an illumination which breaks inextinguishably out of the gateway to the law. Now he no longer has much time to live. Before his death he gathers up in his head all his experiences of the entire time into one question which he has not yet put to the gatekeeper. He waves to him, since he can no longer lift up his stiffening body. The gatekeeper has to bend way down to him, for the difference between them has changed considerably to the disadvantage of the man. “What do you want to know now?” asks the gatekeeper. “You are insatiable.” “Everyone strives after the law,” says the man, “so how is it that in these many years no one except me has requested entry?” The gatekeeper sees that the man is already dying and, in order to reach his diminishing sense of hearing, he shouts at him, “Here no one else can gain entry, since this entrance was assigned only to you. I’m going now to close it.”\"\nNow that we have our text stored as a character vector, we can transform it into a tibble. This process includes removing the title and filtering out empty lines.\nTo remove the title, we can use the str_remove_all() function from the stringr package. Our approach in this case is very direct, as we are matching the exact title line.\nTo remove the empty lines we can use the filter() function from dplyr to match non-empty strings.\nFinally, because we’re transforming the character vector into a tibble, it’s important to add an ID column to preserve the original line order and uniquely identify each line.\nbeforethelaw &lt;- beforethelaw %&gt;%\n    str_remove_all(\"^BEFORE THE LAW$\") # Remove the exact title line (^ = start, $ = end)\n\nbeforethelaw_tibble &lt;- tibble(text = beforethelaw) %&gt;%\n    filter(text != \"\") %&gt;% # Remove empty lines\n    mutate(id = row_number()) # Add an ID column to preserve line order\n\nbeforethelaw_tibble\n\n# A tibble: 1 × 2\n  text                                                                        id\n  &lt;chr&gt;                                                                    &lt;int&gt;\n1 Before the law sits a gatekeeper. To this gatekeeper comes a man from t…     1\nThe result is a two-column tibble: one for the text and another for the line ID.\nNow, we can proceed to perform some preprocessing steps to prepare our text for analysis. This includes converting the text to lowercase, removing punctuation, and tokenizing the text into individual words.",
    "crumbs": [
      "2. Creating a Corpus"
    ]
  },
  {
    "objectID": "02-CreatingACorpus.html#preprocessing-steps",
    "href": "02-CreatingACorpus.html#preprocessing-steps",
    "title": "Creating a Corpus",
    "section": "Preprocessing Steps",
    "text": "Preprocessing Steps\nAlthough a text can be analyzed in its raw form, preprocessing is essential for improving the quality of the analysis. Here are the key steps we’ll perform:\n\nConvert to Lowercase: This helps to standardize the text and avoid treating the same words with different cases as distinct.\nRemove Punctuation: Punctuation marks can interfere with text analysis (e.g., “gatekeeper.” would be considered different from “gatekeeper”), so we’ll remove them.\nTokenization: This is the process of splitting the text into individual words or tokens, which is crucial for most text analysis tasks.\n\nLet’s implement these preprocessing steps using dplyr, stringr, and tidytext. This approach allows us to chain multiple operations together:\n\nlibrary(tidytext) # We'll need this for tokenization\n\nbeforethelaw_preprocessed &lt;- beforethelaw_tibble %&gt;%\n    mutate(text = str_to_lower(text)) %&gt;%        # Convert to lowercase\n    mutate(text = str_remove_all(text, \"[[:punct:]]\")) %&gt;%  # Remove punctuation\n    unnest_tokens(word, text)                    # Tokenization into individual words\n\nbeforethelaw_preprocessed\n\n# A tibble: 640 × 2\n      id word      \n   &lt;int&gt; &lt;chr&gt;     \n 1     1 before    \n 2     1 the       \n 3     1 law       \n 4     1 sits      \n 5     1 a         \n 6     1 gatekeeper\n 7     1 to        \n 8     1 this      \n 9     1 gatekeeper\n10     1 comes     \n# ℹ 630 more rows\n\n\nWe’ve transformed our single-row tibble into a long 640-row tibble, where each row represents a single word from the original text. The unnest_tokens() function from the tidytext package is particularly useful here, as it automatically handles tokenization and creates a new row for each word.\nNote that this number of rows matches the word count from the previous episode. However, this alignment won’t always occur. Depending on text complexity, basic word counting and tokenization can produce different results. For example, tokenization might split contractions (“don’t” → “don” + “t”) or treat hyphenated words (“twenty-one”) as separate tokens, while a simple word count would treat them as single units.\nDepending on the purposes of your analysis, you may want to perform additional preprocessing steps, such as removing stop words (common words like “the,” “and,” “is” that may not carry significant meaning for analysis). Let’s remove stop words for this example using the tidytext package:\n\nbeforethelaw_reduced &lt;- beforethelaw_preprocessed %&gt;%\n    anti_join(stop_words, by = \"word\") # anti_join removes words that match the stop_words list\n\nbeforethelaw_reduced\n\n# A tibble: 164 × 2\n      id word      \n   &lt;int&gt; &lt;chr&gt;     \n 1     1 law       \n 2     1 sits      \n 3     1 gatekeeper\n 4     1 gatekeeper\n 5     1 country   \n 6     1 gain      \n 7     1 entry     \n 8     1 law       \n 9     1 gatekeeper\n10     1 grant     \n# ℹ 154 more rows\n\n\n\n\n\n\n\n\nNote\n\n\n\nStop word removal isn’t always necessary. For tasks like authorship attribution or sentiment analysis, these “common” words can actually provide valuable information about writing style or tone.\n\n\nThis new tibble has 164 rows, meaning we’ve reduced our original text by 75% by removing stop words. This is important to keep in mind, as preprocessing can improve analysis quality by reducing noise and focusing on relevant terms, but it can also result in a loss of context or meaning that may be important for certain types of analysis.",
    "crumbs": [
      "2. Creating a Corpus"
    ]
  }
]